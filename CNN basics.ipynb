{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7397 - acc: 0.5050     \n",
      "Epoch 2/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7024 - acc: 0.5310     \n",
      "Epoch 3/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6896 - acc: 0.5630     \n",
      "Epoch 4/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6852 - acc: 0.5600     \n",
      "Epoch 5/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6768 - acc: 0.6030     \n",
      "Epoch 6/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6600 - acc: 0.6090     \n",
      "Epoch 7/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6439 - acc: 0.6150     \n",
      "Epoch 8/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6401 - acc: 0.6150     \n",
      "Epoch 9/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6299 - acc: 0.6550     \n",
      "Epoch 10/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6236 - acc: 0.6690     \n",
      "Epoch 11/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6086 - acc: 0.6720     \n",
      "Epoch 12/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5997 - acc: 0.6800     \n",
      "Epoch 13/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5924 - acc: 0.6860     \n",
      "Epoch 14/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5801 - acc: 0.7040     \n",
      "Epoch 15/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5866 - acc: 0.6880     \n",
      "Epoch 16/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5597 - acc: 0.7200     \n",
      "Epoch 17/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5664 - acc: 0.7240     \n",
      "Epoch 18/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5536 - acc: 0.7210     \n",
      "Epoch 19/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5434 - acc: 0.7300     \n",
      "Epoch 20/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5381 - acc: 0.7340     \n",
      "Epoch 21/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5266 - acc: 0.7600     \n",
      "Epoch 22/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5190 - acc: 0.7490     \n",
      "Epoch 23/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5122 - acc: 0.7730     \n",
      "Epoch 24/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5000 - acc: 0.7750     \n",
      "Epoch 25/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4930 - acc: 0.7870     \n",
      "Epoch 26/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4888 - acc: 0.7890     \n",
      "Epoch 27/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4677 - acc: 0.7890     \n",
      "Epoch 28/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4536 - acc: 0.8030     \n",
      "Epoch 29/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4652 - acc: 0.7900     \n",
      "Epoch 30/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4424 - acc: 0.8100     \n",
      "Epoch 31/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4417 - acc: 0.8020     \n",
      "Epoch 32/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4399 - acc: 0.8150     \n",
      "Epoch 33/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4378 - acc: 0.8060     \n",
      "Epoch 34/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4437 - acc: 0.8070     \n",
      "Epoch 35/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4277 - acc: 0.8120     \n",
      "Epoch 36/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3889 - acc: 0.8490     \n",
      "Epoch 37/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4174 - acc: 0.8140     \n",
      "Epoch 38/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4164 - acc: 0.8250     \n",
      "Epoch 39/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3938 - acc: 0.8460     \n",
      "Epoch 40/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3905 - acc: 0.8330     \n",
      "Epoch 41/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3729 - acc: 0.8480     \n",
      "Epoch 42/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3430 - acc: 0.8730     \n",
      "Epoch 43/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3725 - acc: 0.8500     \n",
      "Epoch 44/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3544 - acc: 0.8600     \n",
      "Epoch 45/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3385 - acc: 0.8740     \n",
      "Epoch 46/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3467 - acc: 0.8790     \n",
      "Epoch 47/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3423 - acc: 0.8610     \n",
      "Epoch 48/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3210 - acc: 0.8950     \n",
      "Epoch 49/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3394 - acc: 0.8650     \n",
      "Epoch 50/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3129 - acc: 0.8820     \n",
      "Epoch 51/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3201 - acc: 0.8760     \n",
      "Epoch 52/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3022 - acc: 0.8920     \n",
      "Epoch 53/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3055 - acc: 0.8830     \n",
      "Epoch 54/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2997 - acc: 0.8910     \n",
      "Epoch 55/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2882 - acc: 0.8990     \n",
      "Epoch 56/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2847 - acc: 0.9050     \n",
      "Epoch 57/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2884 - acc: 0.8950     \n",
      "Epoch 58/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2708 - acc: 0.9050     \n",
      "Epoch 59/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2819 - acc: 0.8980     \n",
      "Epoch 60/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2586 - acc: 0.9180     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x225cc77d668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=500))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 500))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=60, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.3594 - acc: 0.1010     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.3028 - acc: 0.1120     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2966 - acc: 0.1190     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2863 - acc: 0.1280     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2733 - acc: 0.1290     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2616 - acc: 0.1490     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2414 - acc: 0.1630     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2254 - acc: 0.1770     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.2098 - acc: 0.1950     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 2.1881 - acc: 0.1970     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x225cc4dc470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=700))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 700))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
