{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7397 - acc: 0.5050     \n",
      "Epoch 2/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7024 - acc: 0.5310     \n",
      "Epoch 3/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6896 - acc: 0.5630     \n",
      "Epoch 4/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6852 - acc: 0.5600     \n",
      "Epoch 5/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6768 - acc: 0.6030     \n",
      "Epoch 6/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6600 - acc: 0.6090     \n",
      "Epoch 7/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6439 - acc: 0.6150     \n",
      "Epoch 8/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6401 - acc: 0.6150     \n",
      "Epoch 9/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6299 - acc: 0.6550     \n",
      "Epoch 10/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6236 - acc: 0.6690     \n",
      "Epoch 11/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6086 - acc: 0.6720     \n",
      "Epoch 12/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5997 - acc: 0.6800     \n",
      "Epoch 13/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5924 - acc: 0.6860     \n",
      "Epoch 14/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5801 - acc: 0.7040     \n",
      "Epoch 15/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5866 - acc: 0.6880     \n",
      "Epoch 16/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5597 - acc: 0.7200     \n",
      "Epoch 17/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5664 - acc: 0.7240     \n",
      "Epoch 18/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5536 - acc: 0.7210     \n",
      "Epoch 19/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5434 - acc: 0.7300     \n",
      "Epoch 20/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5381 - acc: 0.7340     \n",
      "Epoch 21/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5266 - acc: 0.7600     \n",
      "Epoch 22/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5190 - acc: 0.7490     \n",
      "Epoch 23/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5122 - acc: 0.7730     \n",
      "Epoch 24/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.5000 - acc: 0.7750     \n",
      "Epoch 25/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4930 - acc: 0.7870     \n",
      "Epoch 26/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4888 - acc: 0.7890     \n",
      "Epoch 27/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4677 - acc: 0.7890     \n",
      "Epoch 28/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4536 - acc: 0.8030     \n",
      "Epoch 29/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4652 - acc: 0.7900     \n",
      "Epoch 30/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4424 - acc: 0.8100     \n",
      "Epoch 31/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4417 - acc: 0.8020     \n",
      "Epoch 32/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4399 - acc: 0.8150     \n",
      "Epoch 33/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4378 - acc: 0.8060     \n",
      "Epoch 34/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4437 - acc: 0.8070     \n",
      "Epoch 35/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4277 - acc: 0.8120     \n",
      "Epoch 36/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3889 - acc: 0.8490     \n",
      "Epoch 37/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4174 - acc: 0.8140     \n",
      "Epoch 38/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.4164 - acc: 0.8250     \n",
      "Epoch 39/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3938 - acc: 0.8460     \n",
      "Epoch 40/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3905 - acc: 0.8330     \n",
      "Epoch 41/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3729 - acc: 0.8480     \n",
      "Epoch 42/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3430 - acc: 0.8730     \n",
      "Epoch 43/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3725 - acc: 0.8500     \n",
      "Epoch 44/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3544 - acc: 0.8600     \n",
      "Epoch 45/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3385 - acc: 0.8740     \n",
      "Epoch 46/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3467 - acc: 0.8790     \n",
      "Epoch 47/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3423 - acc: 0.8610     \n",
      "Epoch 48/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3210 - acc: 0.8950     \n",
      "Epoch 49/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3394 - acc: 0.8650     \n",
      "Epoch 50/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3129 - acc: 0.8820     \n",
      "Epoch 51/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3201 - acc: 0.8760     \n",
      "Epoch 52/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3022 - acc: 0.8920     \n",
      "Epoch 53/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.3055 - acc: 0.8830     \n",
      "Epoch 54/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2997 - acc: 0.8910     \n",
      "Epoch 55/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2882 - acc: 0.8990     \n",
      "Epoch 56/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2847 - acc: 0.9050     \n",
      "Epoch 57/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2884 - acc: 0.8950     \n",
      "Epoch 58/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2708 - acc: 0.9050     \n",
      "Epoch 59/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2819 - acc: 0.8980     \n",
      "Epoch 60/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.2586 - acc: 0.9180     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x225cc77d668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=500))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# model.add(Activation('softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 500))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=60, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.3331 - acc: 0.0900     \n",
      "Epoch 2/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.3018 - acc: 0.1160     \n",
      "Epoch 3/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.2998 - acc: 0.1080     \n",
      "Epoch 4/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.2953 - acc: 0.1210     \n",
      "Epoch 5/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.2791 - acc: 0.1200     \n",
      "Epoch 6/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.2685 - acc: 0.1410     \n",
      "Epoch 7/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.2453 - acc: 0.1480     \n",
      "Epoch 8/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.2243 - acc: 0.1650     \n",
      "Epoch 9/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.1986 - acc: 0.1930     \n",
      "Epoch 10/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.1639 - acc: 0.2090     \n",
      "Epoch 11/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.1286 - acc: 0.2340     \n",
      "Epoch 12/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.1077 - acc: 0.2480     \n",
      "Epoch 13/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.0844 - acc: 0.2470     \n",
      "Epoch 14/60\n",
      "1000/1000 [==============================] - 0s - loss: 2.0412 - acc: 0.2890     \n",
      "Epoch 15/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.9990 - acc: 0.3150     \n",
      "Epoch 16/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.9778 - acc: 0.3120     \n",
      "Epoch 17/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.9353 - acc: 0.3520     \n",
      "Epoch 18/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.8944 - acc: 0.3890     \n",
      "Epoch 19/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.8514 - acc: 0.4030     \n",
      "Epoch 20/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.8255 - acc: 0.4080     \n",
      "Epoch 21/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.7847 - acc: 0.4570     \n",
      "Epoch 22/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.7575 - acc: 0.4580     \n",
      "Epoch 23/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.7073 - acc: 0.4800     \n",
      "Epoch 24/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.6727 - acc: 0.5090     \n",
      "Epoch 25/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.6391 - acc: 0.5000     \n",
      "Epoch 26/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.6058 - acc: 0.5290     \n",
      "Epoch 27/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.5586 - acc: 0.5420     \n",
      "Epoch 28/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.5416 - acc: 0.5420     \n",
      "Epoch 29/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.5036 - acc: 0.5780     \n",
      "Epoch 30/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.4493 - acc: 0.6070     \n",
      "Epoch 31/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.4140 - acc: 0.6050     \n",
      "Epoch 32/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.3773 - acc: 0.6330     \n",
      "Epoch 33/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.3527 - acc: 0.6400     \n",
      "Epoch 34/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.3172 - acc: 0.6500     \n",
      "Epoch 35/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.2901 - acc: 0.6710     \n",
      "Epoch 36/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.2773 - acc: 0.6450     \n",
      "Epoch 37/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.2207 - acc: 0.6920     \n",
      "Epoch 38/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.1876 - acc: 0.6970     \n",
      "Epoch 39/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.1567 - acc: 0.7050     \n",
      "Epoch 40/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.1388 - acc: 0.7220     \n",
      "Epoch 41/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.1111 - acc: 0.7080     \n",
      "Epoch 42/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.0786 - acc: 0.7360     \n",
      "Epoch 43/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.0598 - acc: 0.7280     \n",
      "Epoch 44/60\n",
      "1000/1000 [==============================] - 0s - loss: 1.0196 - acc: 0.7330     \n",
      "Epoch 45/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.9863 - acc: 0.7630     \n",
      "Epoch 46/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.9685 - acc: 0.7400     \n",
      "Epoch 47/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.9474 - acc: 0.7640     \n",
      "Epoch 48/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.9197 - acc: 0.7800     \n",
      "Epoch 49/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.8760 - acc: 0.8050     \n",
      "Epoch 50/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.8693 - acc: 0.7860     \n",
      "Epoch 51/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.8485 - acc: 0.8040     \n",
      "Epoch 52/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.8241 - acc: 0.8200     \n",
      "Epoch 53/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.8031 - acc: 0.8290     \n",
      "Epoch 54/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7711 - acc: 0.8300     \n",
      "Epoch 55/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7432 - acc: 0.8420     \n",
      "Epoch 56/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7280 - acc: 0.8570     \n",
      "Epoch 57/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.7086 - acc: 0.8440     \n",
      "Epoch 58/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6972 - acc: 0.8600     \n",
      "Epoch 59/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6652 - acc: 0.8690     \n",
      "Epoch 60/60\n",
      "1000/1000 [==============================] - 0s - loss: 0.6643 - acc: 0.8620     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x225ccbe76d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=700))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 700))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=60, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
